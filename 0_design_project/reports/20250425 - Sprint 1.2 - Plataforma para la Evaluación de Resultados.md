---
created: 20250411 05:04
update: 20250508-01:53
summary: 
status: 
link: 
tags: 
---
Eres un/a ingeniero/a de software senior, experto/a en arquitecturas modulares plug and play con gesti√≥n de estrategias din√°micas mediante orquestadores jer√°rquicos.
Tu misi√≥n es analizar y mejorar el proyecto de control de p√©ndulo RL-Agent-Factory para solucionar los problemas se√±alados en el ‚Äú20250425 - Sprint 1.2 - Plataforma para la Evaluaci√≥n de Resultados‚Äù


## üîç An√°lisis del Proyecto Actual

### 1. **Arquitectura General**

- La app se encuentra muy bien estructurada y organizada en pesta√±as.
- Usa `summary.xlsx`, m√∫ltiples JSON de episodios y `metadata.json`.
- Utiliza `app_utils.py` para carga de datos, extracci√≥n y animaci√≥n.
- Carga todos los datos de episodios seleccionados en memoria (esto es el cuello de botella actual).
- Gran parte del contenido ya est√° cacheado o estructurado modularmente, lo cual es una excelente base para escalar.

### 2. **Problemas actuales**

- **Carga de episodios completa**: Al cargar todos los episodios en memoria, el rendimiento se ve severamente afectado para grandes simulaciones.
- **Falta de exploraci√≥n comparativa**: No se permite comparar resultados por par√°metros f√°cilmente.
- **Exploraci√≥n general d√©bil**: Falta de panel de exploraci√≥n param√©trica para el `summary`.

---
# ‚úÖ PLAN DE MEJORAS INTEGRAL PARA LA APP DE RESULTADOS PID-RL

---
## üß± OBJETIVOS PRINCIPALES

1. **Reducir carga en memoria y aumentar rendimiento**.
2. **Permitir exploraci√≥n visual eficiente y comparativa** de grandes simulaciones.
3. **Aprovechar al m√°ximo los nuevos datos registrados por timestep y episodio**.
4. **Mejorar la modularidad y extensibilidad del sistema para que cada m√©todo sea un orquestador de estrategias din√°micas con gesti√≥n de componentes `plug and play`**.
5. **Preservar la experiencia interactiva con configuraciones de gr√°ficos personalizables**.

---
## üìÅ ESTRUCTURA GENERAL DE CARGA Y DISPONIBILIDAD DE DATOS

| Fuente de datos                 | Carga inicial            | Modo de acceso                         | Carga en memoria     |
| ------------------------------- | ------------------------ | -------------------------------------- | -------------------- |
| `summary.xlsx`                  | ‚úÖ al seleccionar carpeta | Se mantiene en cach√© (`session_state`) | ‚úÖ                    |
| `metadata.json`                 | ‚úÖ al seleccionar carpeta | Config y setup general                 | ‚úÖ                    |
| `simulation_data_*.json`        | ‚ùå diferido               | Carga bajo demanda por episodio        | ‚ö†Ô∏è Solo uno a la vez |
| `agent_state_episode_*.json`    | ‚ùå diferido               | Carga bajo demanda en "Agent State"    | ‚ö†Ô∏è selectivo         |
| `q_summary.xlsx`, `counts.xlsx` | ‚ùå bajo demanda           | Carga desde bot√≥n en pesta√±a 3         | ‚ö†Ô∏è selectivo         |

---

## üß© MODIFICACIONES ESPEC√çFICAS POR PESTA√ëAS

---

### 1. üè† **"Introduction"** (basado en summary)

#### üîß Cambios Estructurales

- A√±adir **una l√≠nea divisoria** bajo la tabla `describe()`.
- Mostrar dos **paneles paralelos A y B**, cada uno con:
    - A√±adir **selector de episodios para filtrado**
        - `episode`, `episode_time`, `performance`, `total_reward`, `avg_stability_score`, `final_epsilon`, `final_learning_rate`.
    - A√±adir **selector de variables para filtrado**.
        - `termination_reason`, `reward_mode`, `reset_gains`, etc.
- Mostrar√°:
    - Conteo de episodios por panel.
    - Estad√≠sticas comparadas del resto de variables (`avg_reward`, `avg_stability_score`, `avg_duration`, etc.).

---

### 2. üìä **"Performance Overview"** (basado en summary)

#### üß© Estructura de pesta√±a:

1. **Gr√°ficos actuales**:
    - Termination Distribution
    - Total Reward vs Episode
    - Episode Duration vs Episode
    - Performance vs Episode
2. **Nuevo gr√°fico generado por el usuario**:
    - Filtrar datos por `termination_reason` o no
    - Selector din√°mico:
        - Eje X: `episode`, `epsilon`, `learning_rate`, `gain_step`, `episode_duration`, `total_reward`, `performance`
        - Eje Y: `final_kp`, `final_ki`, `final_kd`, `avg_stability_score`, `total_agent_decisions`, `episode_duration`, `total_reward`, `performance`
	- Configuraci√≥n de par√°metros del gr√°fico.
    - Bot√≥n "Generar gr√°fico".
3. **Nuevo gr√°fico boxplot generado por el usuario**:
    - Filtrar datos por `termination_reason`
    - Selector din√°mico:
        - Eje X: `episode`, `epsilon`, `learning_rate`, `gain_step`, `episode_duration`, `total_reward`, `performance`
        - Eje Y:  `pendulum_angle`, `pendulum_velocity`, `cart_position`, `cart_velocity`, `kp`, `ki`, `kd`, `force`, `reward`, `error`, `stability_score`, `mu`, `sigma`, `q_value_kp`, `q_value_ki`, `q_value_kd`, `q_visit_count_kp`, `q_visit_count_ki`, `q_visit_count_kd`, `virtual_force_kp`, `virtual_force_ki`, `virtual_force_kd` (si existen), `virtual_reward_kp`, `virtual_reward_ki`, `virtual_reward_kd` (si existen), `baseline_value_kp`, `baseline_value_ki`, `baseline_value_kd` y `baseline_visit_count_kp`, `baseline_visit_count_ki`, `baseline_visit_count_kd` (si existen),`td_error_kp`, `td_error_ki`, `td_error_kd` (si existen)
	- Configuraci√≥n de par√°metros del gr√°fico.
    - Bot√≥n "Generar gr√°fico".

---

### 3. üåê **Nueva pesta√±a: "Training Performance"**

#### üîß Objetivo:

Visualizaci√≥n de **tablas o heatmaps de Q-tables, baseline B(s) y visit counts** (para las tablas mantener la funcionalidad actual de colorear el valor mayor en cada fila)

#### üîß Componentes:

- Selector con episodios disponibles
- Bot√≥n para cargar archivos externos 
- Selector:
    - Tipo: `tables` o `heatmaps` 
    - Variable: `q_table`o `baseline_table`
    - Ganancia: `kp`, `ki`, `kd`
- Personalizador gr√°fico
- Bot√≥n para guardar imagen


---

### 4. üß† **Nueva pesta√±a: "Advanced Performance"**

#### üîß Objetivo:

Explorar relaciones entre **hiperpar√°metros** y **resultados de simulaci√≥n**.

#### üîß Componentes:
- En panel lateral:
    - Filtro por `termination_reason`
- Selector de variables de entrada (`epsilon`, `learning_rate`, `gain_step`, `final_kp`, `final_ki`, `final_kd`, `learn_agent_duration_ms`, `total_agent_decisions` )
- Selector de m√©tricas (`episode_duration`, `total_reward`, `performance`, `avg_stability_score`)
- Gr√°fico:
    - Heatmap de correlaci√≥n
    - Boxplots por categor√≠a
    - Scatter 3D (opcional)
- Permitir comparar hasta 3 variables independientes contra una dependiente

---

### 5. üîç **"Episode Details"

#### üîß Objetivo:

Modificar la lectura de datos de episodio pero mantener exactamente las caracter√≠sticas y funcionalidades de las tablas y gr√°ficos actuales de esta page

#### üîß Cambios estructurales:

- Carga diferida por episodio.
- Utilizar `summary.xlsx` para 
- En panel lateral:
    - Filtro por `termination_reason`
    - Selector: `episode`
    - Show:
        - `episode_duration`, `termination_reason`, `total_reward`, `performance`, `avg_stability_score`, `final_kp`, `final_ki`, `final_kd`, `epsilon`, `learning_rate`, `total_agent_decisions`
- Bot√≥n "Cargar JSON del episodio".
- Liberar memoria al cambiar de pesta√±a.

#### üîß Exploraci√≥n visual:

- Dividir variables en grupos:
    - **Sistema**: `time`, `pendulum_angle`, `pendulum_velocity`, `cart_position`, `cart_velocity`, `force`
    - **Controlador**: `kp`, `ki`, `kd`,`error`, `integral_error`, `derivative_error`
    - **Agente**: `action_*`, `q_value_*`, `baseline_value_*`, `td_error_*`, 
    - **Estabilidad y recompensa:** `reward`, `cumulative_reward`, `stability_score`, `Adaptive Statistics` para cada par√°metro su `mu` y `sigma`
    - **Entrenamiento**: `id_agent_decision`, `learn_agent_duration_ms`, `gain_step`


---

### 6. ‚öôÔ∏è **"Analysis Configurator"**

- Se mantiene como est√°, desarrollo futuro